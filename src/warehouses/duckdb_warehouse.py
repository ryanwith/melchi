import duckdb
import datetime
from .abstract_warehouse import AbstractWarehouse

class DuckDBWarehouse(AbstractWarehouse):
    def __init__(self, config):
        super().__init__("duckdb")  # Initialize with the warehouse type
        self.config = config
        self.connection = None

    def connect(self):
        self.connection = duckdb.connect(self.config['database'])

    def disconnect(self):
        if self.connection:
            self.connection.close()

    def begin_transaction(self):
        self.connection.begin()

    def commit_transaction(self):
        self.connection.commit()

    def rollback_transaction(self):
        self.connection.rollback()

    def get_schema(self, full_table_name):
        result = self.connection.execute(f"PRAGMA table_info('{full_table_name}')")
        return [(col[1], col[2], col[5]) for col in result.fetchall()]

    def create_table(self, schema_name, table_name, schema):
        primary_keys = []
        column_definitions = []

        # create a schema if needed
        self.connection.execute(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")

        # build a list of primary keys
        for column in schema:
            if column[2] == 'Y':
                primary_keys.append(column[0])

        for column in schema:
            definition = f"{column[0]} {column[1]}"

            # add PRIMARY KEY designator to the primary key column if there's one or fewer pks
            if column[2] == "Y" and len(primary_keys) < 2:
                definition += " PRIMARY KEY"
            column_definitions.append(definition)

        # create a composite primary key at the end if there are multiple
        if len(primary_keys) >= 2:
            column_definitions.append(f"PRIMARY KEY ({", ".join(primary_keys)})")   

        # Will used autogenerated keys from snowflake and bigquery if a primary key isn't set
        if len(primary_keys) == 0:
            pk_name = "MELCHI_ROW_ID"
            primary_keys.append(pk_name)
            column_definitions.append(f"{pk_name} VARCHAR PRIMARY KEY")

        create_table_query = f"CREATE TABLE {schema_name}.{table_name} ({", ".join(column_definitions)});"
        print(create_table_query)

        # create the actual table
        self.connection.execute(create_table_query)

        current_timestamp = datetime.datetime.now()

        print(primary_keys)
        update_logs = f"""INSERT INTO {self.config["cdc_metadata_schema"]}.table_info VALUES (
            '{schema_name}', '{table_name}', '{current_timestamp}', '{current_timestamp}', {self.format_primary_keys(primary_keys)}
        )"""

        print(update_logs)

        self.connection.execute(update_logs)

    def get_data(self, table_name):
        result = self.connection.execute(f"SELECT * FROM {table_name}")
        return result.fetchall()

    def insert_data(self, table_name, data):
        # Implementation for inserting data into DuckDB
        pass

    def setup_target_environment(self):
        self.connection.execute(f"CREATE SCHEMA IF NOT EXISTS {self.config["cdc_metadata_schema"]};")
        self.connection.execute(f"""
            CREATE TABLE IF NOT EXISTS {self.config["cdc_metadata_schema"]}.table_info
                (table_schema varchar, table_name varchar, created_at timestamp, updated_at timestamp, primary_keys varchar[], PRIMARY KEY (table_schema, table_name));
        """)

    def format_primary_keys(self, primary_keys):
        if len(primary_keys) == 1:
            return f"['{primary_keys[0]}']"
        else:
            return f"[{", ".join(primary_keys.map(lambda pk: f"'{pk}'"))}]"