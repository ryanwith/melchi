import duckdb
import datetime
from .abstract_warehouse import AbstractWarehouse

class DuckDBWarehouse(AbstractWarehouse):
    def __init__(self, config):
        super().__init__("duckdb")  # Initialize with the warehouse type
        self.config = config
        self.connection = None

    def connect(self):
        self.connection = duckdb.connect(self.config['database'])

    def disconnect(self):
        if self.connection:
            self.connection.close()

    def begin_transaction(self):
        self.connection.begin()

    def commit_transaction(self):
        self.connection.commit()

    def rollback_transaction(self):
        self.connection.rollback()

    def get_schema(self, table_info):
        result = self.connection.execute(f"PRAGMA table_info('{self.get_full_table_name(table_info)}')")
        return [(col[1], col[2], col[5]) for col in result.fetchall()]

    def create_table(self, table_info, schema):
        schema_name = table_info["schema"]
        table_name = table_info["table"]
        primary_keys = []
        column_definitions = []

        # create a schema if needed
        self.connection.execute(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")

        # build a list of primary keys
        for column in schema:
            if column[2] == 'Y':
                primary_keys.append(column[0])

        for column in schema:
            definition = f"{column[0]} {column[1]}"
            column_definitions.append(definition) 

        # Will used autogenerated keys from snowflake and bigquery if a primary key isn't set
        # we do not actually set the primary keys in duckdb as it is too eager for enforcement in transactions
        if len(primary_keys) == 0:
            pk_name = "MELCHI_ROW_ID"
            primary_keys.append(pk_name)
            column_definitions.append(f"{pk_name} VARCHAR")

        create_table_query = f"CREATE TABLE {schema_name}.{table_name} ({", ".join(column_definitions)});"

        # create the actual table
        self.connection.execute(create_table_query)

        current_timestamp = datetime.datetime.now()

        update_logs = f"""INSERT INTO {self.get_cdc_table_info_table_name()} VALUES (
            '{schema_name}', '{table_name}', '{current_timestamp}', '{current_timestamp}', {self.convert_list_to_duckdb_syntax(primary_keys)}
        )"""

        self.connection.execute(update_logs)

    def get_data(self, table_name):
        result = self.connection.execute(f"SELECT * FROM {table_name};")
        return result.fetchall()

    def get_data_as_df(self, table_name):
        pass

    def insert_data(self, table_name, data):
        # Implementation for inserting data into DuckDB
        pass

    def setup_target_environment(self):
        self.connection.execute(f"CREATE SCHEMA IF NOT EXISTS {self.config["cdc_metadata_schema"]};")
        self.connection.execute(f"""
            CREATE TABLE IF NOT EXISTS {self.config["cdc_metadata_schema"]}.table_info
                (schema_name varchar, table_name varchar, created_at timestamp, updated_at timestamp, primary_keys varchar[], PRIMARY KEY (schema_name, table_name));
        """)

    def create_cdc_stream(self, table_info):
        pass

    def get_changes(self, table_info):
        pass

    def get_full_table_name(self, table_info):
        return f"{table_info["schema"]}.{table_info["table"]}"

    def get_stream_name(self, table_info):
        pass

    def sync_table(self, table_info, df):
        full_table_name = self.get_full_table_name(table_info)
        temp_table_name = table_info["table"] + "_melchi_cdc"

        # somehow this grabs the dataframe but i am not sure how
        self.connection.execute(f"CREATE OR REPLACE TEMP TABLE {temp_table_name} AS (SELECT * FROM df)")    
        columns_to_insert = []
        for row in self.get_schema(table_info):
            columns_to_insert.append(row[0])
        formatted_columns = ", ".join(columns_to_insert)
        formatted_primary_keys = ", ".join(self.get_primary_keys(table_info))
        delete_sql_statement = f"""DELETE FROM {full_table_name}
            WHERE ({formatted_primary_keys}) IN 
            (
                SELECT {formatted_primary_keys}
                FROM {temp_table_name}
                WHERE melchi_metadata_action = 'DELETE'
            );
        """
        insert_sql_statement = f"""INSERT INTO {full_table_name}
            SELECT {formatted_columns} FROM {temp_table_name}
            WHERE melchi_metadata_action = 'INSERT'
        """
        
        self.connection.execute(delete_sql_statement)
        self.connection.execute(insert_sql_statement)
        self.update_cdc_tracker(table_info)
        # add update table info query

        self.connection.execute(f"DROP TABLE {temp_table_name}")            

    def convert_list_to_duckdb_syntax(self, standard_list):
        return f"[{", ".join(list(map(lambda item: f"'{item}'", standard_list)))}]"
    
    def get_primary_keys(self, table_info):
        cdc_table_info_table = self.get_cdc_table_info_table_name()
        primary_keys = self.connection.execute(f"""
            SELECT primary_keys FROM {cdc_table_info_table}
                WHERE table_name = '{table_info["table"]}' and schema_name = '{table_info["schema"]}'
        """).fetchone()[0]
        return primary_keys
    
    def cleanup_cdc_for_table(self, table_info):
        pass

    def get_cdc_table_info_table_name(self):
        return f"{self.config["cdc_metadata_schema"]}.table_info"
    
    def update_cdc_tracker(self, table_info):
        where_clause = f"WHERE table_name = '{table_info["table"]}' and schema_name = '{table_info["schema"]}'"
        self.connection.execute(f"UPDATE {self.get_cdc_table_info_table_name()} SET updated_at = current_timestamp {where_clause} ")
    # def insert_cdc_query()